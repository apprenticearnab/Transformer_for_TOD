{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file9 = open(\"test_file2.txt\", \"w\") \n",
    "L = [\"This is a file containing test dataset results like , context , predicted and target belief states , joint and slot accuracy for each batch and overall joint and slot accuracy \\n\"] \n",
    "file9.writelines(L)\n",
    "file9.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import encoding\n",
    "from model import make_model\n",
    "from model import LabelSmoothing\n",
    "from model import NoamOpt\n",
    "from model import data_gen\n",
    "from accuracy import joint_accuracy\n",
    "from accuracy import slot_accuracy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = ByteLevelBPETokenizer('simpletod/vocab.json','simpletod/merges.txt')\n",
    "tokenizer.add_special_tokens([\"<PAD>\",\"<|belief|>\",\" <|endofbelief|>\",\"<|context|>\",\" <|user|> \",\" <|system|> \",\"<|endofcontext|>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer('vocab.json','merges.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_tok = tokenizer.encode(\"<PAD>\").ids.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ele(elem_list):\n",
    "  for ele in elem_list:\n",
    "    if tokenizer.decode([ele],skip_special_tokens=False) == '<PAD>':\n",
    "      return\n",
    "    yield tokenizer.decode([ele],skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, loss_compute):\n",
    "    \"Standard Training and Logging Function\"\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    loss1 = []\n",
    "    index = []\n",
    "    ref1 = []\n",
    "    cand1 = []\n",
    "    file1 = open(\"test_file2.txt\", \"a\")\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        reference = []\n",
    "        candidate = []\n",
    "        ref2 = []\n",
    "        cand2 = []\n",
    "        out = model.forward(batch.src.to(device), batch.trg.to(device), \n",
    "                            batch.src_mask.to(device), batch.trg_mask.to(device))\n",
    "        loss = loss_compute(out, batch.trg_y.to(device), batch.ntokens.to(device))\n",
    "        loss1.append(loss)\n",
    "        index.append(i)\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        #file1.write(\"Batch No. - %d \\n\" % (i+1))\n",
    "        max , idx = torch.max(model.generator(out),dim=2)\n",
    "        pred2 = idx.tolist()\n",
    "        for d in range(len(batch.src.tolist())):\n",
    "                file1.write(''.join(list(print_ele(batch.src.tolist()[d]))) + \"\\n\")#tokenizer.decode(batch.src.tolist()[d],skip_special_tokens=False) + \"\\n\")\n",
    "                file1.write(\"<|belief|>\" + tokenizer.decode(pred2[d],skip_special_tokens=True) + \" <|endofbelief|>\" + \"\\n\")\n",
    "                file1.write(\"<|belief|>\" + tokenizer.decode(batch.trg_y.tolist()[d],skip_special_tokens=True) + \" <|endofbelief|>\" + \"\\n\")\n",
    "                #ref1.append(tokenizer.decode(pred2[d],skip_special_tokens=True).split(','))\n",
    "                #cand1.append(tokenizer.decode(batch.trg_y.tolist()[d],skip_special_tokens=True).split(','))\n",
    "                #ref2.append(tokenizer.decode(pred2[d],skip_special_tokens=True).split(','))\n",
    "                #cand2.append(tokenizer.decode(batch.trg_y.tolist()[d],skip_special_tokens=True).split(','))\n",
    "        #file1.write(\"Joint Accuracy - %f \\n\" % joint_accuracy(cand2,ref2,d_c = False,type2_c = False))\n",
    "        #file1.write(\"Slot Accuracy - %f \\n\" % slot_accuracy(cand2,ref2))\n",
    "        if i % 200 == 1:\n",
    "            elapsed = time.time() - start\n",
    "            max , idx = torch.max(model.generator(out),dim=2)\n",
    "            a = idx.tolist()\n",
    "            b = batch.trg_y.tolist()\n",
    "            print(idx.size())\n",
    "            print(batch.trg_y.size())\n",
    "            for id in a:\n",
    "                reference.append(tokenizer.decode(id,skip_special_tokens=True).split(','))\n",
    "            for p in batch.trg_y.tolist():\n",
    "                candidate.append(tokenizer.decode(p,skip_special_tokens=True).split(',')) \n",
    "            print(reference)\n",
    "            print(candidate)\n",
    "            accuracy = joint_accuracy(candidate,reference,d_c = False,type2_c = False)\n",
    "            slt_accuracy = slot_accuracy(candidate,reference)\n",
    "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f Joint Accuracy: %f Slot Accuracy: %f\" %\n",
    "                    (i, loss / batch.ntokens, tokens / elapsed,accuracy,slt_accuracy))\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "    #file1.write(\"Overall Joint Accuracy - %f \\n\" % joint_accuracy(cand1,ref1,d_c = False,type2_c = False))\n",
    "    #file1.write(\"Overall Slot Accuracy - %f \\n\" % slot_accuracy(cand1,ref1))\n",
    "    file1.close()\n",
    "    return total_loss / total_tokens,accuracy,slt_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), \n",
    "                              y.contiguous().view(-1)) / norm\n",
    "        loss.backward()\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        return loss.item() * norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 30000\n",
    "model = torch.load('simpletod/dialog_NLP.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alipu\\Documents\\TransformerDialog_ArnabM\\model.py:264: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(p)\n"
     ]
    }
   ],
   "source": [
    "V = 30000\n",
    "model = make_model(V, V, N=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial one**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alipu\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 92])\n",
      "torch.Size([10, 92])\n",
      "[[' restaurant food italian ', ' restaurant pricerange expensive ', ' restaurant name curry brasserie ', ' restaurant area centre ', ' attraction type cherry'], [' restaurant food italian ', ' restaurant pricerange expensive ', ' restaurant name curry brasserie ', ' restaurant area centre ', ' attraction type cherry'], [' restaurant food italian ', ' restaurant pricerange expensive ', ' restaurant name curry brasserie ', ' restaurant area centre ', ' attraction type cherry'], [' restaurant food italian ', ' restaurant pricerange expensive ', ' restaurant name curry brasserie ', ' restaurant area centre ', ' attraction type cherry'], [' restaurant pricerange moderate'], [' restaurant food moderate ', ' restaurant area centre'], [' restaurant food moderate ', ' restaurant area centre'], [' restaurant food moderate ', ' restaurant area centre'], [' restaurant food chinese ', ' restaurant pricerange moderate ', ' restaurant area hotel kettle ', ' restaurant area centre ', ' train type museum sports ', ' attraction area centre'], [' restaurant food chinese ', ' restaurant pricerange moderate ', ' attraction name grafton kettle ', ' restaurant area centre ', ' attraction type museum ', ' attraction name centre']]\n",
      "[[' restaurant food indian ', ' restaurant pricerange expensive ', ' restaurant name saffron brasserie ', ' restaurant area centre ', ' attraction name nusha'], [' restaurant food indian ', ' restaurant pricerange expensive ', ' restaurant name saffron brasserie ', ' restaurant area centre ', ' attraction name nusha'], [' restaurant food indian ', ' restaurant pricerange expensive ', ' restaurant name saffron brasserie ', ' restaurant area centre ', ' attraction name nusha'], [' restaurant food indian ', ' restaurant pricerange expensive ', ' restaurant name saffron brasserie ', ' restaurant area centre ', ' attraction name nusha'], [' restaurant pricerange moderate'], [' restaurant pricerange moderate ', ' restaurant area centre'], [' restaurant pricerange moderate ', ' restaurant area centre'], [' restaurant pricerange moderate ', ' restaurant area centre'], [' restaurant food british ', ' restaurant pricerange moderate ', ' restaurant name copper kettle ', ' restaurant area centre ', ' attraction type multiple sports ', ' attraction area centre'], [' restaurant food british ', ' restaurant pricerange moderate ', ' restaurant name copper kettle ', ' restaurant area centre ', ' attraction type architecture ', ' attraction area centre']]\n",
      "Epoch Step: 1 Loss: 0.139203 Tokens per Sec: 3435.615479 Joint Accuracy: 0.100000 Slot Accuracy: 0.200000\n",
      "torch.Size([10, 92])\n",
      "torch.Size([10, 92])\n",
      "[[' restaurant food the ', ' restaurant book time 1 ', ' restaurant book day tuesday ', ' restaurant book time 11:15 ', ' train destination cambridge ', ' train day tuesday ', ' train arriveBy 11:15 ', ' train departure london'], [' restaurant food the ', ' restaurant book time 6 ', ' restaurant book day tuesday ', ' restaurant book time 11:15 ', ' train destination cambridge ', ' train day tuesday ', ' train arriveBy 11:15 ', ' train departure leicester train book people 6'], [' restaurant food the ', ' restaurant book time 6 ', ' restaurant book day tuesday ', ' restaurant book time 11:15 ', ' train destination cambridge ', ' train day tuesday ', ' train arriveBy 11:15 ', ' train departure london train book people 6'], [' hotel pricerange moderate ', ' restaurant area centre'], [' restaurant food chinese ', ' restaurant pricerange moderate restaurant name centre'], [' restaurant food chinese ', ' restaurant pricerange moderate restaurant name centre'], [' restaurant food chinese ', ' restaurant pricerange moderate restaurant name the pizza kitchen and bar restaurant area centre'], [' restaurant food chinese ', ' restaurant pricerange moderate ', ' restaurant name the pizza kitchen and bar ', ' train area centre ', ' train leaveAt 11:00 ', ' train day wednesday ', ''], [' restaurant food chinese ', ' restaurant pricerange moderate ', ' train name the pizza kitchen and bar ', ' train area centre ', ' train leaveAt 11:00 ', ' train destination cambridge airport ', ' train day wednesday ', ' train departure cambridge'], [' restaurant food chinese ', ' restaurant pricerange moderate ', ' restaurant name the pizza kitchen and bar ', ' restaurant area centre ', ' train leaveAt 11:00 ', ' train destination cambridge airport ', ' train day wednesday ', ' train departure cambridge train book people 4']]\n",
      "[[' restaurant name cocum ', ' restaurant book people 6 ', ' restaurant book day tuesday ', ' restaurant book time 11:00 ', ' train destination cambridge ', ' train day tuesday ', ' train arriveBy 08:15 ', ' train departure broxbourne'], [' restaurant name cocum ', ' restaurant book people 6 ', ' restaurant book day tuesday ', ' restaurant book time 11:00 ', ' train destination cambridge ', ' train day tuesday ', ' train arriveBy 08:15 ', ' train departure broxbourne ', ' train book people 6'], [' restaurant name cocum ', ' restaurant book people 6 ', ' restaurant book day tuesday ', ' restaurant book time 11:00 ', ' train destination cambridge ', ' train day tuesday ', ' train arriveBy 08:15 ', ' train departure broxbourne ', ' train book people 6'], [' restaurant pricerange moderate ', ' restaurant area centre'], [' restaurant food irish ', ' restaurant pricerange moderate ', ' restaurant area centre'], [' restaurant food gastropub ', ' restaurant pricerange moderate ', ' restaurant area centre'], [' restaurant food gastropub ', ' restaurant pricerange moderate ', ' restaurant name cow pizza kitchen and bar ', ' restaurant area centre'], [' restaurant food gastropub ', ' restaurant pricerange moderate ', ' restaurant name cow pizza kitchen and bar ', ' restaurant area centre ', ' train leaveAt 20:00 ', ' train day friday'], [' restaurant food gastropub ', ' restaurant pricerange moderate ', ' restaurant name cow pizza kitchen and bar ', ' restaurant area centre ', ' train leaveAt 20:00 ', ' train destination stansted airport ', ' train day friday ', ' train departure cambridge'], [' restaurant food gastropub ', ' restaurant pricerange moderate ', ' restaurant name cow pizza kitchen and bar ', ' restaurant area centre ', ' train leaveAt 20:40 ', ' train destination stansted airport ', ' train day friday ', ' train departure cambridge ', ' train book people 3']]\n",
      "Epoch Step: 201 Loss: 0.190192 Tokens per Sec: 7140.140137 Joint Accuracy: 0.000000 Slot Accuracy: 0.300000\n",
      "torch.Size([10, 92])\n",
      "torch.Size([10, 92])\n",
      "[[' taxi leaveAt none ', ' taxi departure the of a time ', ' taxi arriveBy 17:00 ', ' restaurant food indian ', ' restaurant pricerange expensive ', ' restaurant area curry ', ' restaurant area west ', ' restaurant book time ', ':00 ', ' restaurant book day wednesday ', ' restaurant book people 6 ', ' attraction type museum ', ' attraction area none of a time attraction area west'], [' taxi leaveAt none ', ' taxi departure the of a time ', ' taxi arriveBy 17:00 ', ' restaurant food indian ', ' restaurant pricerange expensive ', ' restaurant area curry ', ' restaurant area west ', ' restaurant book time ', ':00 ', ' restaurant book day wednesday ', ' restaurant book people 6 ', ' attraction type museum ', ' attraction area none of a time attraction area west'], [' attraction type saint college'], [' attraction type saint college'], [' hotel area 4 ', ' hotel internet yes ', ' hotel type saint college'], [' hotel area yes ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel type guesthouse attraction type saint college'], [' hotel area yes ', ' hotel stars moderate ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel type guesthouse attraction type saint college'], [' hotel name university house ', ' hotel area yes ', ' hotel stars cheap ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel type guesthouse attraction type saint college'], [' hotel name university house ', ' hotel area yes ', ' hotel stars cheap ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel book guesthouse ', ' hotel book stay 1 ', ' hotel book day thursday ', ' hotel book stay 4 ', ' attraction type saint college'], [' hotel name university house ', ' hotel area yes ', ' hotel pricerange cheap ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel book guesthouse ', ' hotel book stay 1 ', ' hotel book day thursday ', ' hotel book stay 4 ', ' attraction type saint college']]\n",
      "[[' taxi destination meghna ', ' taxi departure whale of a time ', ' taxi arriveBy 19:45 ', ' restaurant food indian ', ' restaurant pricerange moderate ', ' restaurant name meghna ', ' restaurant area west ', ' restaurant book time 19:45 ', ' restaurant book day saturday ', ' restaurant book people 2 ', ' attraction type entertainment ', ' attraction name whale of a time ', ' attraction area dontcare'], [' taxi destination meghna ', ' taxi departure whale of a time ', ' taxi arriveBy 19:45 ', ' restaurant food indian ', ' restaurant pricerange moderate ', ' restaurant name meghna ', ' restaurant area west ', ' restaurant book time 19:45 ', ' restaurant book day saturday ', ' restaurant book people 2 ', ' attraction type entertainment ', ' attraction name whale of a time ', ' attraction area dontcare'], [' attraction name christ college'], [' attraction name christ college'], [' hotel stars 4 ', ' hotel internet free ', ' attraction name christ college'], [' hotel parking free ', ' hotel stars 4 ', ' hotel internet free ', ' hotel type guesthouse ', ' attraction name christ college'], [' hotel parking free ', ' hotel pricerange cheap ', ' hotel stars 4 ', ' hotel internet free ', ' hotel type guesthouse ', ' attraction name christ college'], [' hotel name autumn house ', ' hotel parking free ', ' hotel pricerange cheap ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel type guesthouse ', ' attraction name christ college'], [' hotel name autumn house ', ' hotel parking free ', ' hotel pricerange cheap ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel type guesthouse ', ' hotel book people 4 ', ' hotel book day friday ', ' hotel book stay 5 ', ' attraction name christ college'], [' hotel name autumn house ', ' hotel parking free ', ' hotel pricerange cheap ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel type guesthouse ', ' hotel book people 4 ', ' hotel book day friday ', ' hotel book stay 5 ', ' attraction name christ college']]\n",
      "Epoch Step: 401 Loss: 0.389124 Tokens per Sec: 7155.575195 Joint Accuracy: 0.000000 Slot Accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 92])\n",
      "torch.Size([10, 92])\n",
      "[[' hotel name yes ', ' hotel pricerange moderate ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel book stay 4 ', ' hotel book day wednesday ', ' hotel book people 1 ', ' attraction type cambridge art'], [' hotel leaveAt 17:00 ', ' taxi destination cambridge guest house ', ' taxi departure alexander art ', ' hotel name yes ', ' hotel pricerange moderate ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel book stay 1 ', ' hotel book day thursday ', ' hotel book people 1 ', ' attraction type cambridge art'], [' hotel leaveAt 17:00 ', ' taxi destination cambridge guest house ', ' taxi departure alexander art ', ' hotel name yes ', ' hotel pricerange moderate ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel book stay 1 ', ' hotel book day thursday ', ' hotel book people 1 ', ' attraction type cambridge art'], [' hotel area north ', ' hotel type guesthouse'], [' hotel area north ', ' hotel pricerange moderate ', ' hotel internet guesthouse'], [' hotel area north ', ' hotel stars moderate ', ' hotel stars 4 ', ' hotel internet guesthouse'], [' hotel name north ', ' hotel parking yes ', ' hotel pricerange moderate ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel type guesthouse ', ' hotel book stay 4 hotel book day wednesday ', ' hotel book people 1'], [' hotel name north ', ' hotel parking yes ', ' hotel pricerange moderate ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel type guesthouse ', ' hotel book stay 4 ', ' hotel book day wednesday ', ' hotel book people 1'], [' hotel name north ', ' hotel parking yes ', ' hotel pricerange moderate ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel type guesthouse ', ' hotel book stay 4 ', ' hotel book day thursday ', ' hotel book people 1 attraction destination wednesday ', ' train departure cambridge new street train book people 1'], [' hotel name north ', ' hotel parking yes ', ' hotel pricerange moderate ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel type guesthouse ', ' hotel book stay 4 ', ' hotel book day thursday ', ' hotel book people 1 ', ' train leaveAt 11:00 ', ' train destination wednesday ', ' train departure cambridge new street train book people 1']]\n",
      "[[' hotel parking yes ', ' hotel pricerange moderate ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel book stay 1 ', ' hotel book day wednesday ', ' hotel book people 1 ', ' attraction name byard art'], [' taxi leaveAt 21:30 ', ' taxi destination acorn guest house ', ' taxi departure byard art ', ' hotel parking yes ', ' hotel pricerange moderate ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel book stay 1 ', ' hotel book day wednesday ', ' hotel book people 1 ', ' attraction name byard art'], [' taxi leaveAt 21:30 ', ' taxi destination acorn guest house ', ' taxi departure byard art ', ' hotel parking yes ', ' hotel pricerange moderate ', ' hotel stars 4 ', ' hotel internet yes ', ' hotel book stay 1 ', ' hotel book day wednesday ', ' hotel book people 1 ', ' attraction name byard art'], [' hotel area north ', ' hotel type guesthouse'], [' hotel area north ', ' hotel pricerange expensive ', ' hotel type guesthouse'], [' hotel area north ', ' hotel pricerange moderate ', ' hotel stars 4 ', ' hotel type guesthouse'], [' hotel area north ', ' hotel parking dontcare ', ' hotel pricerange moderate ', ' hotel stars 4 ', ' hotel internet dontcare ', ' hotel type guesthouse ', ' hotel book stay 3 ', ' hotel book day wednesday ', ' hotel book people 1'], [' hotel area north ', ' hotel parking dontcare ', ' hotel pricerange moderate ', ' hotel stars 4 ', ' hotel internet dontcare ', ' hotel type guesthouse ', ' hotel book stay 3 ', ' hotel book day wednesday ', ' hotel book people 1'], [' hotel area north ', ' hotel parking dontcare ', ' hotel pricerange moderate ', ' hotel stars 4 ', ' hotel internet dontcare ', ' hotel type guesthouse ', ' hotel book stay 3 ', ' hotel book day wednesday ', ' hotel book people 1 ', ' train day wednesday ', ' train departure birmingham new street ', ' train book people none'], [' hotel area north ', ' hotel parking dontcare ', ' hotel pricerange moderate ', ' hotel stars 4 ', ' hotel internet dontcare ', ' hotel type guesthouse ', ' hotel book stay 3 ', ' hotel book day wednesday ', ' hotel book people 1 ', ' train leaveAt 14:30 ', ' train day wednesday ', ' train departure birmingham new street ', ' train book people none']]\n",
      "Epoch Step: 601 Loss: 0.187464 Tokens per Sec: 6973.576660 Joint Accuracy: 0.100000 Slot Accuracy: 0.100000\n",
      "tensor(0.1995, device='cuda:0')\n",
      "0.1\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n",
    "\n",
    "\n",
    "s7,t7 = encoding('simpletod/Processed_data/simptod/context_test.txt','simpletod/Processed_data/simptod/belief_test.txt',400)\n",
    "l2,a3,sa3 = run_epoch(data_gen(V, 10, 737,s7,t7), model.to(device), \n",
    "                    SimpleLossCompute(model.generator, criterion, None))\n",
    "print(l2)\n",
    "print(a3)\n",
    "print(sa3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final one**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    words = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decode(memory, src_mask, \n",
    "                           Variable(words), \n",
    "                           Variable(subsequent_mask(words.size(1))\n",
    "                                    .type_as(src.data)))\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.item()\n",
    "        words = torch.cat([words, \n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "    if words.dim() == 2:\n",
    "        words = words.squeeze(0)\n",
    "        words = words.tolist()\n",
    "        \n",
    "    sen_idx = [w for w in words]\n",
    "    sentence = tokenizer.decode(sen_idx,skip_special_tokens=True)#' '.join([rev_word_map[sen_idx[k]] for k in range(len(sen_idx))])\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s4,t4 = encoding('simpletod/Processed_data/simptod/context_test.txt','simpletod/Processed_data/simptod/belief_test.txt',400)\n",
    "file1 = open(\"test_file27.txt\", \"a\")\n",
    "for i in range(7370):\n",
    "    src = Variable(torch.unsqueeze(s4[i,:400],0))\n",
    "    src_mask = Variable(torch.ones(1, 1, 400) )\n",
    "    s = greedy_decode(model.to(device), src.to(device), src_mask.to(device), 400, start)\n",
    "    file1.write(''.join(list(print_ele([w for w in s4[i][:400]]))) + \"\\n\")#tokenizer.decode(batch.src.tolist()[d],skip_special_tokens=False) + \"\\n\")\n",
    "    file1.write(\"<|belief|>\" + s + \" <|endofbelief|>\" + \"\\n\")\n",
    "    file1.write(\"<|belief|>\" + tokenizer.decode([w for w in t4[i][:400]],skip_special_tokens=True) + \" <|endofbelief|>\" + \"\\n\")\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating JSON file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('test_file27.txt','r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "#raw=raw.lower()\n",
    "output = raw.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'target_turn_belief':[] ,'generated_turn_belief':[] ,'model_context':[] }\n",
    "#dict = dict.fromkeys(['target_turn_belief','generated_turn_belief','model_context'])\n",
    "for i in range(1,len(output)-1,3):\n",
    "    dict['target_turn_belief'].append((' '.join(output[i+2].split()[1:-1]).split(',')))\n",
    "    dict['generated_turn_belief'].append((' '.join(output[i+1].split()[1:-1]).split(',')))\n",
    "    dict['model_context'].append((' '.join(output[i].split()[1:-1]).split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {i:{'target_turn_belief':dict['target_turn_belief'][i:i+10],'generated_turn_belief':dict['generated_turn_belief'][i:i+10],'model_context':dict['model_context'][i:i+10]} for i in range(0,len(dict['target_turn_belief']),10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"eval_file17.json\", \"w\") as outfile:  \n",
    "    json.dump(dict1, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint accuracy: 0.1875\n"
     ]
    }
   ],
   "source": [
    "!python simpletod/compute_joint_acc.py --eval_file eval_file17.json --type2_cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint accuracy: 0.175\n"
     ]
    }
   ],
   "source": [
    "!python simpletod/compute_joint_acc.py --eval_file eval_file17.json "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
